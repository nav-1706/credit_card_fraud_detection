# -*- coding: utf-8 -*-
"""Credit_card.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19sS7YfMSwxIEv5RlGuNR1K9Bp1YaXYwL

Importing the Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Loading the dataset to a Pandas DataFrame

credit_card_data = pd.read_csv('creditcard.csv')

# Printing the first 5 rows of the datasets

# credit_card_data.head()

# Printing the last 5 rows of the datasets

# credit_card_data.tail()

# Getting the Dataset Info

# credit_card_data.info()

# Checking for the distribution of legit transactions & fraudulent transactions

credit_card_data['Class'].value_counts()

"""Highy Unbalanced Dataset

*   0: Legal Transaction
*   1: Fraud Transaction
"""

# Seperating the data for Analysis

legit = credit_card_data[credit_card_data.Class == 0] # whole row will be stored
fraud = credit_card_data[credit_card_data.Class == 1]

# Checking for the Dimmesions

print(legit.shape) # (rows, cols)
print(fraud.shape)

# Getting the statistical measure of the legit data

legit.Amount.describe()

"""*   25% of the Amount is less than 5.990000
*   50% of the Amount is less than 23.000000
*   75% of the Amount is less than 79.200000
"""

# Getting the statistical measure of the fraud data

fraud.Amount.describe()

# Comparing the values for both transaction

credit_card_data.groupby('Class').mean()

"""Performing Under Sampling

Build a sample database conataining similar distributuion of Legit transactions and Fraud Transaction

*   Number of Legit Transactions: 201715
*   Number of Fraud Transactions: 387
"""

# Taking random 387 rows from the legit database

legit_sample = legit.sample(n=387)

"""Concatination two data frames: legit_sample and fraud"""

new_data = pd.concat([legit_sample, fraud], axis = 0)

# axis=0 means row-wise concatenation (i.e., it adds rows).
# The result is a new DataFrame new_data that stacks fraud under legit_sample
# To create a balanced dataset.

print(new_data.shape)

# Printing the first 5 rows of the dataset

new_data.head()

# Printing the last 5 rows of the dataset

new_data.tail()

# Checking the Uniformaity of the new_data

new_data['Class'].value_counts()

# Comparing the values for both transaction in new_data

new_data.groupby('Class').mean()

# Spilliting the Data into Fearures and Target

X = new_data.drop(columns='Class', axis = 1)
Y = new_data['Class']

"""`X = new_data.drop(columns='Class', axis=1)`

*   Removes the 'Class' column from new_data
*   axis=1 means you're dropping a column (not a row)
*   So X contains all columns except 'Class', which are used as features for training a modelm

`Y = new_data['Class']`

*   Extracts only the 'Class' column as the target
*   n fraud detection datasets like this, the 'Class' column typically has:
  *   0 for legitimate transactions
  *   1 for fraudulent transactions
"""

print(X.shape)
print(Y.shape)

# print(X) # Uncommenting this line will print the entire feature set, which can be very large
# print(Y) # Uncommenting this line will print the entire target set, which is usually just 0s and 1s

"""Split the data into Training Data and Test Data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state = 2)

"""**‚úÖ What it does:** It splits your dataset into training and testing sets.

---

**üîç Breakdown of each parameter:**

*   X: Features (input variables)
*   Y: Labels/Target (fraud or not)


---



`üß™ test_size=0.2`


*   20% of the data goes to the test set
*   80% to the training set


---

`‚öñÔ∏è stratify=Y`


*   Ensures class distribution remains the same in both train and test sets.
*   This is especially important in imbalanced datasets like fraud detection (e.g., 99% legit, 1% fraud).


Without stratify=Y, the test set might randomly contain only legit transactions, making evaluation useless.


---

`üé≤ random_state=2`


*   Sets the random seed for reproducibility
*   If you run the code multiple times with the same random_state, you‚Äôll get the same split every time

---

| Variable  | Contains                            |
| --------- | ----------------------------------- |
| `X_train` | 80% of the feature data             |
| `X_test`  | 20% of the feature data             |
| `Y_train` | Corresponding target labels (train) |
| `Y_test`  | Corresponding target labels (test)  |

---

**üß† Summary:**
* A training set (to train the model)
* A test set (to evaluate the model)
* With balanced fraud/legit ratios (stratify=Y)
"""

print(X.shape, X_train.shape, X_test.shape)

print(Y.shape, Y_train.shape, Y_test.shape)

"""Traing Model: Logistic Regression


"""

model = LogisticRegression()
model = LogisticRegression(max_iter=10000)  # Default is 100
model.fit(X_train, Y_train)

"""**Model Training**

Accuracy Score
"""

# Use the trained logistic regression model to make predictions on the training data
# This returns an array of predicted class labels (0 or 1) for each training sample
X_train_prediction = model.predict(X_train)

# Calculate the accuracy of the model on the training data
# Compares predicted values with true values (Y_train)
# Accuracy = (Number of correct predictions) / (Total predictions)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print('Accuracy on Training data : ', training_data_accuracy)

# Use the trained logistic regression model to make predictions on the test data
# This gives an array of predicted class labels (0 or 1) for each test sample
X_test_prediction = model.predict(X_test)

# Calculate the accuracy of the model on the test data
# Compares predicted values with true values (Y_test)
# Accuracy = (Number of correct predictions) / (Total predictions)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy score on Test Data : ', test_data_accuracy)

